# ğŸ§  Cerebrium Model Deployment with FastAPI + ONNX

This project demonstrates deploying a deep learning model (ONNX format) via a FastAPI app, containerized using Docker, and optionally deployed on [Cerebrium](https://www.cerebrium.ai/).

---

## ğŸ“ Project Structure

```
cerebrium-model-deployment/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ app.py # FastAPI server
â”‚ â”œâ”€â”€ model.py # Preprocessing and ONNX model loader
â”‚ â”œâ”€â”€ convert_to_onnx.py # PyTorch â†’ ONNX conversion script
â”‚ â”œâ”€â”€ test.py # Local testing script
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ weights/
â”‚ â”œâ”€â”€ model.onnx
â”‚ â””â”€â”€ pytorch_model_weights.pth
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```


---

## ğŸš€ Run Locally

### 1. Install Python dependencies
```bash
pip install -r requirements.txt
```

### 2. Run the FastAPI server
```
uvicorn app.app:app --reload
```
Then open: http://127.0.0.1:8000/docs

## ğŸ³ Build & Run with Docker
### 1. Build Docker image
```
docker build -t my-model-app .
```
### 2.Run the container
```
docker run -p 8000:8000 my-model-app
```
## â˜ï¸ Deploy on Cerebrium
### 1. Install Cerebrium CLI
```
pip install cerebrium --upgrade
```

### 2. Initialize project
```
cerebrium init my-project-name
```

### 3. Deploy
```
cerebrium deploy
```
Make sure to include your weights and cerebrium.toml file in the root directory.

## ğŸ“¦ Requirements
Install all Python dependencies via:
```
pip install -r requirements.txt
```

## ğŸ“„ License
This project is for internal/company deployment via Cerebrium.

---

### âœ… **Step 2: Add, Commit & Push**

Once added:

```bash
git add README.md
git commit -m "Add README.md"
git push
